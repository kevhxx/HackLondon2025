{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Kevin Xu**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "仅存在于 features 的 ID: set()\n",
      "仅存在于 patient_info 的 ID: {66, 99, 4, 69, 100, 103, 40, 106, 12, 76, 16, 17, 80, 54, 25, 28, 29, 62}\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "import pandas as pd\n",
    "import pyarrow\n",
    "from tsfresh.feature_selection.selection import select_features\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tsfresh.utilities.dataframe_functions import impute\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression  \n",
    "from sklearn.model_selection import GridSearchCV  \n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectFdr, f_classif \n",
    "\n",
    "# Load data with proper decimal handling (for European-style CSV)\n",
    "features = pl.read_csv(\"data/features_processed1.csv\")\n",
    "patient_info = pl.read_csv(\"data/patient_info_processed.csv\", ignore_errors=True)\n",
    "\n",
    "# 打印两个文件的 ID 差异\n",
    "features_ids = features[\"ID\"].unique().to_list()\n",
    "patient_info_ids = patient_info[\"ID\"].unique().to_list()\n",
    "print(\"仅存在于 features 的 ID:\", set(features_ids) - set(patient_info_ids))\n",
    "print(\"仅存在于 patient_info 的 ID:\", set(patient_info_ids) - set(features_ids))\n",
    "\n",
    "# 直接筛选两个 DataFrame 的交集 ID\n",
    "dataX = features.filter(pl.col(\"ID\").is_in(patient_info[\"ID\"]))\n",
    "dataY = patient_info.filter(pl.col(\"ID\").is_in(features[\"ID\"]))\n",
    "\n",
    "# 通过 Join 对齐 ID\n",
    "merged = features.join(patient_info, on=\"ID\", how=\"inner\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Processing Data Seperately**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 筛选 HRV=0 的数据并确保 ID 唯一性（统一 ID 类型为字符串）\n",
    "data_hrv0 = (\n",
    "    merged.filter(pl.col(\"HRV\") == 0)\n",
    "    .with_columns(pl.col(\"ID\").cast(pl.Utf8))  # 关键修复：统一类型\n",
    "    .unique(subset=[\"ID\"], keep=\"first\")\n",
    "    .sort(\"ID\")\n",
    ")\n",
    "\n",
    "# 分割特征和目标变量（保留 ACC_TIME）\n",
    "dataX_hrv0 = data_hrv0.select(pl.exclude([\"ADHD\", \"HRV_TIME\", \"HRV\"]))\n",
    "dataY_hrv0 = data_hrv0.select([\"ID\", \"ADHD\"])\n",
    "\n",
    "# 时间编码函数（保持不变）\n",
    "def cyclical_time_encoding_polars(df: pl.DataFrame) -> pl.DataFrame:\n",
    "    return (\n",
    "        df.with_columns(\n",
    "            pl.col(\"ACC_TIME\").str.split(\":\").list.eval(\n",
    "                pl.element().cast(pl.UInt32).fill_null(0)\n",
    "            ).alias(\"time_parts\"),\n",
    "        )\n",
    "        .with_columns(\n",
    "            (pl.col(\"time_parts\").list.get(0)*3600 \n",
    "             + pl.col(\"time_parts\").list.get(1)*60 \n",
    "             + pl.col(\"time_parts\").list.get(2)\n",
    "            ).alias(\"total_seconds\")\n",
    "        )\n",
    "        .with_columns(\n",
    "            (2 * np.pi * pl.col(\"total_seconds\") / 86400).alias(\"radians\")\n",
    "        )\n",
    "        .with_columns(\n",
    "            pl.col(\"radians\").sin().alias(\"ACC_TIME_SIN\"),\n",
    "            pl.col(\"radians\").cos().alias(\"ACC_TIME_COS\")\n",
    "        )\n",
    "        .drop([\"time_parts\", \"total_seconds\", \"radians\", \"ACC_TIME\"])\n",
    "    )\n",
    "\n",
    "dataX_hrv0 = cyclical_time_encoding_polars(dataX_hrv0)\n",
    "\n",
    "# 索引对齐函数（确保类型一致性）\n",
    "def align_polars_data(X: pl.DataFrame, y: pl.DataFrame) -> tuple[pl.DataFrame, pl.DataFrame]:\n",
    "    \"\"\"强制 ID 类型一致后对齐\"\"\"\n",
    "    # 统一类型\n",
    "    X = X.with_columns(pl.col(\"ID\").cast(pl.Utf8))\n",
    "    y = y.with_columns(pl.col(\"ID\").cast(pl.Utf8))\n",
    "    \n",
    "    # 获取共同 ID\n",
    "    common_ids = (\n",
    "        X.select(\"ID\")\n",
    "        .join(y.select(\"ID\"), on=\"ID\", how=\"semi\")\n",
    "        .unique()\n",
    "        .sort(\"ID\")\n",
    "    )\n",
    "    return (\n",
    "        X.join(common_ids, on=\"ID\").sort(\"ID\"),\n",
    "        y.join(common_ids, on=\"ID\").sort(\"ID\")\n",
    "    )\n",
    "\n",
    "dataX_hrv0, dataY_hrv0 = align_polars_data(dataX_hrv0, dataY_hrv0)\n",
    "\n",
    "# 类型转换（确保 ADHD 为 Float32）\n",
    "dataY_hrv0 = dataY_hrv0.with_columns(\n",
    "    pl.col(\"ADHD\").cast(pl.Float32).fill_null(-1)\n",
    ")\n",
    "\n",
    "# 最终验证\n",
    "assert dataX_hrv0[\"ID\"].equals(dataY_hrv0[\"ID\"]), f\"\"\"\n",
    "索引未对齐详情：\n",
    "- X 类型: {dataX_hrv0['ID'].dtype}, Y 类型: {dataY_hrv0['ID'].dtype}\n",
    "- 前5个ID对比：\n",
    "  X: {dataX_hrv0[\"ID\"].head(5).to_list()}\n",
    "  Y: {dataY_hrv0[\"ID\"].head(5).to_list()}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (47, 812)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>ID</th><th>ACC__variance_larger_than_standard_deviation</th><th>ACC__has_duplicate_max</th><th>ACC__has_duplicate_min</th><th>ACC__has_duplicate</th><th>ACC__sum_values</th><th>ACC__abs_energy</th><th>ACC__mean_abs_change</th><th>ACC__mean_change</th><th>ACC__mean_second_derivative_central</th><th>ACC__median</th><th>ACC__mean</th><th>ACC__length</th><th>ACC__standard_deviation</th><th>ACC__variation_coefficient</th><th>ACC__variance</th><th>ACC__skewness</th><th>ACC__kurtosis</th><th>ACC__root_mean_square</th><th>ACC__absolute_sum_of_changes</th><th>ACC__longest_strike_below_mean</th><th>ACC__longest_strike_above_mean</th><th>ACC__count_above_mean</th><th>ACC__count_below_mean</th><th>ACC__last_location_of_maximum</th><th>ACC__first_location_of_maximum</th><th>ACC__last_location_of_minimum</th><th>ACC__first_location_of_minimum</th><th>ACC__percentage_of_reoccurring_values_to_all_values</th><th>ACC__percentage_of_reoccurring_datapoints_to_all_datapoints</th><th>ACC__sum_of_reoccurring_values</th><th>ACC__sum_of_reoccurring_data_points</th><th>ACC__ratio_value_number_to_time_series_length</th><th>ACC__sample_entropy</th><th>ACC__maximum</th><th>ACC__minimum</th><th>ACC__benford_correlation</th><th>&hellip;</th><th>ACC__permutation_entropy__dimension_7__tau_1</th><th>ACC__matrix_profile__feature_&quot;&quot;&quot;&quot;min&quot;&quot;&quot;&quot;__threshold_0.98</th><th>ACC__matrix_profile__feature_&quot;&quot;&quot;&quot;max&quot;&quot;&quot;&quot;__threshold_0.98</th><th>ACC__matrix_profile__feature_&quot;&quot;&quot;&quot;mean&quot;&quot;&quot;&quot;__threshold_0.98</th><th>ACC__matrix_profile__feature_&quot;&quot;&quot;&quot;median&quot;&quot;&quot;&quot;__threshold_0.98</th><th>ACC__matrix_profile__feature_&quot;&quot;&quot;&quot;25&quot;&quot;&quot;&quot;__threshold_0.98</th><th>ACC__matrix_profile__feature_&quot;&quot;&quot;&quot;75&quot;&quot;&quot;&quot;__threshold_0.98</th><th>SEX</th><th>AGE</th><th>ACC</th><th>ACC_DAYS</th><th>HRV_HOURS</th><th>CPT_II</th><th>ADD</th><th>BIPOLAR</th><th>UNIPOLAR</th><th>ANXIETY</th><th>SUBSTANCE</th><th>OTHER</th><th>CT</th><th>MDQ_POS</th><th>WURS</th><th>ASRS</th><th>MADRS</th><th>HADS_A</th><th>HADS_D</th><th>MED</th><th>MED_Antidepr</th><th>MED_Moodstab</th><th>MED_Antipsych</th><th>MED_Anxiety_Benzo</th><th>MED_Sleep</th><th>MED_Analgesics_Opioids</th><th>MED_Stimulants</th><th>filter_$</th><th>ACC_TIME_SIN</th><th>ACC_TIME_COS</th></tr><tr><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>&hellip;</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>i64</td><td>i64</td><td>i64</td><td>f64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;10&quot;</td><td>1.0</td><td>0.0</td><td>1.0</td><td>1.0</td><td>887574.0</td><td>2.2537724e8</td><td>42.327399</td><td>0.0</td><td>-0.000655</td><td>9.0</td><td>68.401202</td><td>12976.0</td><td>112.65013</td><td>1.646903</td><td>12690.051737</td><td>3.395866</td><td>22.100605</td><td>131.790653</td><td>549198.0</td><td>365.0</td><td>133.0</td><td>4256.0</td><td>8720.0</td><td>0.926942</td><td>0.926865</td><td>1.0</td><td>0.0</td><td>0.901639</td><td>0.999075</td><td>28141.0</td><td>873258.0</td><td>0.009402</td><td>0.18662</td><td>1726.0</td><td>0.0</td><td>0.933277</td><td>&hellip;</td><td>5.878335</td><td>3.534709</td><td>17.137102</td><td>12.516565</td><td>12.927879</td><td>11.304366</td><td>14.140833</td><td>1</td><td>3</td><td>1</td><td>9.0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>1</td><td>1</td><td>0</td><td>0</td><td>42</td><td>38</td><td>16</td><td>10</td><td>5</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0.551937</td><td>-0.833886</td></tr><tr><td>&quot;108&quot;</td><td>1.0</td><td>0.0</td><td>1.0</td><td>1.0</td><td>3.354992e6</td><td>3.1757e9</td><td>171.380145</td><td>0.0</td><td>-0.04343</td><td>143.0</td><td>353.157053</td><td>9500.0</td><td>457.778304</td><td>1.296246</td><td>209560.975545</td><td>1.549465</td><td>2.273884</td><td>578.170286</td><td>1.62794e6</td><td>517.0</td><td>176.0</td><td>3297.0</td><td>6203.0</td><td>0.940526</td><td>0.940421</td><td>1.0</td><td>0.0</td><td>0.960526</td><td>0.999368</td><td>78885.0</td><td>3.336332e6</td><td>0.016</td><td>0.312297</td><td>3637.0</td><td>0.0</td><td>0.963084</td><td>&hellip;</td><td>6.904089</td><td>2.329597</td><td>8.991218</td><td>6.440952</td><td>6.5034</td><td>5.759727</td><td>7.189762</td><td>1</td><td>3</td><td>1</td><td>6.6</td><td>0</td><td>1</td><td>0</td><td>0</td><td>1</td><td>0</td><td>1</td><td>0</td><td>1</td><td>1</td><td>65</td><td>51</td><td>0</td><td>0</td><td>0</td><td>9</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0.442289</td><td>-0.896873</td></tr><tr><td>&quot;13&quot;</td><td>1.0</td><td>0.0</td><td>1.0</td><td>1.0</td><td>3.378861e6</td><td>2.8651e9</td><td>177.520324</td><td>0.0</td><td>0.0</td><td>166.0</td><td>325.422421</td><td>10383.0</td><td>412.357136</td><td>1.267144</td><td>170038.407711</td><td>1.702196</td><td>3.571307</td><td>525.298163</td><td>1.843016e6</td><td>270.0</td><td>50.0</td><td>3913.0</td><td>6470.0</td><td>0.449196</td><td>0.449099</td><td>1.0</td><td>0.0</td><td>0.954248</td><td>0.999326</td><td>79353.0</td><td>3.359021e6</td><td>0.014736</td><td>0.263236</td><td>3418.0</td><td>0.0</td><td>0.986672</td><td>&hellip;</td><td>6.499379</td><td>2.852002</td><td>15.577571</td><td>12.445792</td><td>12.941399</td><td>11.538077</td><td>13.859342</td><td>0</td><td>3</td><td>1</td><td>7.2</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>48</td><td>0</td><td>5</td><td>3</td><td>2</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>1</td><td>1.2246e-16</td><td>-1.0</td></tr><tr><td>&quot;14&quot;</td><td>1.0</td><td>0.0</td><td>1.0</td><td>1.0</td><td>1.743156e6</td><td>1.1998e9</td><td>117.746384</td><td>0.0</td><td>-0.003372</td><td>31.0</td><td>189.555894</td><td>9196.0</td><td>307.462115</td><td>1.622013</td><td>94532.9524</td><td>2.13723</td><td>4.825765</td><td>361.198546</td><td>1.082678e6</td><td>327.0</td><td>100.0</td><td>2692.0</td><td>6504.0</td><td>0.015115</td><td>0.015007</td><td>1.0</td><td>0.0</td><td>0.970803</td><td>0.999565</td><td>59300.0</td><td>1.7356e6</td><td>0.014898</td><td>0.275212</td><td>2150.0</td><td>0.0</td><td>0.987569</td><td>&hellip;</td><td>6.48523</td><td>2.631817</td><td>11.868038</td><td>9.305237</td><td>9.703475</td><td>8.756306</td><td>10.405446</td><td>0</td><td>4</td><td>1</td><td>6.4</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>1</td><td>0</td><td>0</td><td>52</td><td>49</td><td>9</td><td>9</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>-0.5</td><td>-0.866025</td></tr><tr><td>&quot;18&quot;</td><td>1.0</td><td>0.0</td><td>1.0</td><td>1.0</td><td>2.495675e6</td><td>1.7377e9</td><td>122.902955</td><td>0.0</td><td>-0.029895</td><td>57.0</td><td>213.744005</td><td>11676.0</td><td>321.149272</td><td>1.502495</td><td>103136.85473</td><td>2.163544</td><td>5.967227</td><td>385.776301</td><td>1.434892e6</td><td>153.0</td><td>123.0</td><td>3812.0</td><td>7864.0</td><td>0.147482</td><td>0.147396</td><td>1.0</td><td>0.0</td><td>0.974843</td><td>0.999657</td><td>70419.0</td><td>2.485211e6</td><td>0.013618</td><td>0.293919</td><td>2990.0</td><td>0.0</td><td>0.97324</td><td>&hellip;</td><td>6.763202</td><td>2.702909</td><td>11.395531</td><td>8.474024</td><td>8.641447</td><td>7.758865</td><td>9.348692</td><td>0</td><td>2</td><td>1</td><td>8.1</td><td>0</td><td>1</td><td>0</td><td>1</td><td>0</td><td>1</td><td>0</td><td>0</td><td>1</td><td>1</td><td>43</td><td>52</td><td>37</td><td>11</td><td>13</td><td>1</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0.5</td><td>-0.866025</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;72&quot;</td><td>1.0</td><td>0.0</td><td>1.0</td><td>1.0</td><td>2.329983e6</td><td>1.6699e9</td><td>127.529888</td><td>0.000273</td><td>-0.021201</td><td>79.0</td><td>211.970797</td><td>10992.0</td><td>327.085048</td><td>1.543067</td><td>106984.628605</td><td>2.750711</td><td>11.220433</td><td>389.764349</td><td>1.401681e6</td><td>213.0</td><td>82.0</td><td>3542.0</td><td>7450.0</td><td>0.603439</td><td>0.603348</td><td>0.983715</td><td>0.0</td><td>0.97351</td><td>0.999636</td><td>82702.0</td><td>2.317964e6</td><td>0.013737</td><td>0.356675</td><td>3991.0</td><td>0.0</td><td>0.99403</td><td>&hellip;</td><td>6.785565</td><td>1.907301</td><td>10.360375</td><td>7.423277</td><td>7.638297</td><td>6.437911</td><td>8.625025</td><td>1</td><td>2</td><td>1</td><td>7.6</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>25</td><td>28</td><td>10</td><td>5</td><td>5</td><td>1</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0.707107</td><td>-0.707107</td></tr><tr><td>&quot;74&quot;</td><td>1.0</td><td>0.0</td><td>1.0</td><td>1.0</td><td>2.561778e6</td><td>2.3386e9</td><td>136.330167</td><td>0.0</td><td>-0.021813</td><td>42.0</td><td>248.306484</td><td>10317.0</td><td>406.226791</td><td>1.635989</td><td>165020.205379</td><td>2.479431</td><td>8.666597</td><td>476.105362</td><td>1.406382e6</td><td>396.0</td><td>64.0</td><td>3114.0</td><td>7203.0</td><td>0.57759</td><td>0.577493</td><td>1.0</td><td>0.0</td><td>0.967105</td><td>0.999515</td><td>93835.0</td><td>2.544984e6</td><td>0.014733</td><td>0.21202</td><td>4259.0</td><td>0.0</td><td>0.988354</td><td>&hellip;</td><td>6.137602</td><td>2.156442</td><td>11.156693</td><td>8.252393</td><td>8.562514</td><td>7.561757</td><td>9.325718</td><td>0</td><td>2</td><td>1</td><td>7.2</td><td>0</td><td>1</td><td>1</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>40</td><td>42</td><td>9</td><td>3</td><td>2</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0.5</td><td>-0.866025</td></tr><tr><td>&quot;8&quot;</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.114027e6</td><td>7.19229773e8</td><td>110.91615</td><td>0.000653</td><td>-0.016071</td><td>47.0</td><td>181.703963</td><td>6131.0</td><td>290.334329</td><td>1.597843</td><td>84294.022459</td><td>2.497339</td><td>7.776272</td><td>342.505989</td><td>679916.0</td><td>366.0</td><td>65.0</td><td>1893.0</td><td>4238.0</td><td>0.967868</td><td>0.936552</td><td>0.998858</td><td>0.0</td><td>0.973856</td><td>0.999348</td><td>58544.0</td><td>1.106366e6</td><td>0.024955</td><td>0.292656</td><td>2263.0</td><td>0.0</td><td>0.983961</td><td>&hellip;</td><td>6.42847</td><td>10.554882</td><td>20.791346</td><td>17.935688</td><td>18.167298</td><td>16.951096</td><td>18.887614</td><td>0</td><td>2</td><td>1</td><td>4.3</td><td>0</td><td>1</td><td>0</td><td>1</td><td>0</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>70</td><td>63</td><td>19</td><td>17</td><td>4</td><td>1</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>1</td><td>1.2246e-16</td><td>-1.0</td></tr><tr><td>&quot;92&quot;</td><td>1.0</td><td>0.0</td><td>1.0</td><td>1.0</td><td>2.530825e6</td><td>2.2593e9</td><td>152.551494</td><td>0.0</td><td>-0.001302</td><td>59.0</td><td>263.517805</td><td>9604.0</td><td>407.196382</td><td>1.545233</td><td>165808.89379</td><td>2.22725</td><td>6.228762</td><td>485.026316</td><td>1.464952e6</td><td>598.0</td><td>186.0</td><td>3051.0</td><td>6553.0</td><td>0.880779</td><td>0.880675</td><td>1.0</td><td>0.0</td><td>0.980392</td><td>0.999688</td><td>87561.0</td><td>2.52212e6</td><td>0.015931</td><td>0.233238</td><td>3512.0</td><td>0.0</td><td>0.989473</td><td>&hellip;</td><td>6.351625</td><td>5.073497</td><td>29.160531</td><td>22.889814</td><td>22.918779</td><td>21.093454</td><td>25.42621</td><td>1</td><td>2</td><td>1</td><td>6.7</td><td>0</td><td>1</td><td>0</td><td>1</td><td>0</td><td>1</td><td>0</td><td>0</td><td>1</td><td>1</td><td>60</td><td>54</td><td>9</td><td>12</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>-0.932008</td><td>-0.362438</td></tr><tr><td>&quot;96&quot;</td><td>1.0</td><td>0.0</td><td>1.0</td><td>1.0</td><td>1.405197e6</td><td>6.87601867e8</td><td>87.526867</td><td>0.0</td><td>-0.000125</td><td>35.0</td><td>116.875738</td><td>12023.0</td><td>208.639886</td><td>1.785143</td><td>43530.602209</td><td>3.350211</td><td>16.238409</td><td>239.145438</td><td>1.052248e6</td><td>144.0</td><td>46.0</td><td>3243.0</td><td>8780.0</td><td>0.940115</td><td>0.940032</td><td>1.0</td><td>0.0</td><td>0.947761</td><td>0.999418</td><td>48105.0</td><td>1.3899e6</td><td>0.011145</td><td>0.497338</td><td>2845.0</td><td>0.0</td><td>0.972206</td><td>&hellip;</td><td>7.212978</td><td>1.418545</td><td>7.535957</td><td>5.012035</td><td>5.111655</td><td>4.421801</td><td>5.702632</td><td>1</td><td>2</td><td>1</td><td>8.3</td><td>0</td><td>1</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>1</td><td>29</td><td>39</td><td>15</td><td>15</td><td>10</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>-0.548293</td><td>-0.836286</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (47, 812)\n",
       "┌─────┬────────────┬────────────┬────────────┬───┬────────────┬──────────┬────────────┬────────────┐\n",
       "│ ID  ┆ ACC__varia ┆ ACC__has_d ┆ ACC__has_d ┆ … ┆ MED_Stimul ┆ filter_$ ┆ ACC_TIME_S ┆ ACC_TIME_C │\n",
       "│ --- ┆ nce_larger ┆ uplicate_m ┆ uplicate_m ┆   ┆ ants       ┆ ---      ┆ IN         ┆ OS         │\n",
       "│ str ┆ _than_stan ┆ ax         ┆ in         ┆   ┆ ---        ┆ i64      ┆ ---        ┆ ---        │\n",
       "│     ┆ …          ┆ ---        ┆ ---        ┆   ┆ i64        ┆          ┆ f64        ┆ f64        │\n",
       "│     ┆ ---        ┆ f64        ┆ f64        ┆   ┆            ┆          ┆            ┆            │\n",
       "│     ┆ f64        ┆            ┆            ┆   ┆            ┆          ┆            ┆            │\n",
       "╞═════╪════════════╪════════════╪════════════╪═══╪════════════╪══════════╪════════════╪════════════╡\n",
       "│ 10  ┆ 1.0        ┆ 0.0        ┆ 1.0        ┆ … ┆ 0          ┆ 1        ┆ 0.551937   ┆ -0.833886  │\n",
       "│ 108 ┆ 1.0        ┆ 0.0        ┆ 1.0        ┆ … ┆ 0          ┆ 1        ┆ 0.442289   ┆ -0.896873  │\n",
       "│ 13  ┆ 1.0        ┆ 0.0        ┆ 1.0        ┆ … ┆ 1          ┆ 1        ┆ 1.2246e-16 ┆ -1.0       │\n",
       "│ 14  ┆ 1.0        ┆ 0.0        ┆ 1.0        ┆ … ┆ 0          ┆ 1        ┆ -0.5       ┆ -0.866025  │\n",
       "│ 18  ┆ 1.0        ┆ 0.0        ┆ 1.0        ┆ … ┆ 0          ┆ 1        ┆ 0.5        ┆ -0.866025  │\n",
       "│ …   ┆ …          ┆ …          ┆ …          ┆ … ┆ …          ┆ …        ┆ …          ┆ …          │\n",
       "│ 72  ┆ 1.0        ┆ 0.0        ┆ 1.0        ┆ … ┆ 0          ┆ 1        ┆ 0.707107   ┆ -0.707107  │\n",
       "│ 74  ┆ 1.0        ┆ 0.0        ┆ 1.0        ┆ … ┆ 0          ┆ 1        ┆ 0.5        ┆ -0.866025  │\n",
       "│ 8   ┆ 1.0        ┆ 1.0        ┆ 1.0        ┆ … ┆ 0          ┆ 1        ┆ 1.2246e-16 ┆ -1.0       │\n",
       "│ 92  ┆ 1.0        ┆ 0.0        ┆ 1.0        ┆ … ┆ 0          ┆ 1        ┆ -0.932008  ┆ -0.362438  │\n",
       "│ 96  ┆ 1.0        ┆ 0.0        ┆ 1.0        ┆ … ┆ 0          ┆ 1        ┆ -0.548293  ┆ -0.836286  │\n",
       "└─────┴────────────┴────────────┴────────────┴───┴────────────┴──────────┴────────────┴────────────┘"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataX_hrv0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[数据报告] 总样本: 47 | 特征数: 812\n",
      "训练集正样本比例: 24.3% | 测试集正样本比例: 20.0%\n",
      "    x791  x787  x793  x790  x794  x789  x792  x809  x797  x788  ...  \\\n",
      "0    2.0   0.0   2.0   2.0   2.0   2.0   2.0   0.0   0.0   2.0  ...   \n",
      "1    2.0   0.0   2.0   2.0   2.0   2.0   2.0   0.0   0.0   2.0  ...   \n",
      "2    0.0   1.0   0.0   0.0   1.0   0.0   0.0   1.0  52.0   0.0  ...   \n",
      "3    1.0   1.0   0.0   1.0   1.0   0.0   0.0   1.0  15.0   0.0  ...   \n",
      "4    2.0   0.0   2.0   2.0   2.0   2.0   2.0   0.0   0.0   2.0  ...   \n",
      "5    0.0   1.0   0.0   0.0   0.0   0.0   0.0   1.0  38.0   1.0  ...   \n",
      "6    0.0   1.0   0.0   0.0   0.0   0.0   1.0   1.0  28.0   0.0  ...   \n",
      "7    2.0   0.0   2.0   2.0   2.0   2.0   2.0   0.0   0.0   2.0  ...   \n",
      "8    0.0   1.0   1.0   1.0   1.0   0.0   0.0   1.0  62.0   0.0  ...   \n",
      "9    2.0   0.0   2.0   2.0   2.0   2.0   2.0   0.0   0.0   2.0  ...   \n",
      "10   2.0   0.0   2.0   2.0   2.0   2.0   2.0   0.0   0.0   2.0  ...   \n",
      "11   2.0   0.0   2.0   2.0   2.0   2.0   2.0   0.0   0.0   2.0  ...   \n",
      "12   2.0   0.0   2.0   2.0   2.0   2.0   2.0   0.0   0.0   2.0  ...   \n",
      "13   1.0   1.0   0.0   0.0   1.0   1.0   1.0   1.0  46.0   0.0  ...   \n",
      "14   2.0   0.0   2.0   2.0   2.0   2.0   2.0   0.0   0.0   2.0  ...   \n",
      "15   2.0   0.0   2.0   2.0   2.0   2.0   2.0   0.0   0.0   2.0  ...   \n",
      "16   2.0   0.0   2.0   2.0   2.0   2.0   2.0   0.0   0.0   2.0  ...   \n",
      "17   2.0   0.0   2.0   2.0   2.0   2.0   2.0   0.0   0.0   2.0  ...   \n",
      "18   2.0   0.0   2.0   2.0   2.0   2.0   2.0   0.0   0.0   2.0  ...   \n",
      "19   0.0   1.0   1.0   0.0   0.0   0.0   0.0   1.0   0.0   0.0  ...   \n",
      "20   2.0   0.0   2.0   2.0   2.0   2.0   2.0   0.0   0.0   2.0  ...   \n",
      "21   2.0   0.0   2.0   2.0   2.0   2.0   2.0   0.0   0.0   2.0  ...   \n",
      "22   2.0   0.0   2.0   2.0   2.0   2.0   2.0   0.0   0.0   2.0  ...   \n",
      "23   2.0   0.0   2.0   2.0   2.0   2.0   2.0   0.0   0.0   2.0  ...   \n",
      "24   0.0   1.0   0.0   1.0   0.0   0.0   0.0   1.0  42.0   1.0  ...   \n",
      "25   2.0   0.0   2.0   2.0   2.0   2.0   2.0   0.0   0.0   2.0  ...   \n",
      "26   2.0   0.0   2.0   2.0   2.0   2.0   2.0   0.0   0.0   2.0  ...   \n",
      "27   2.0   0.0   2.0   2.0   2.0   2.0   2.0   0.0   0.0   2.0  ...   \n",
      "28   2.0   0.0   2.0   2.0   2.0   2.0   2.0   0.0   0.0   2.0  ...   \n",
      "29   1.0   0.0   1.0   0.0   0.0   0.0   1.0   1.0  38.0   0.0  ...   \n",
      "30   1.0   1.0   1.0   0.0   1.0   1.0   0.0   1.0  34.0   0.0  ...   \n",
      "31   1.0   1.0   0.0   0.0   1.0   1.0   0.0   1.0  54.0   0.0  ...   \n",
      "32   1.0   1.0   1.0   0.0   1.0   1.0   1.0   1.0  63.0   0.0  ...   \n",
      "33   2.0   0.0   2.0   2.0   2.0   2.0   2.0   0.0   0.0   2.0  ...   \n",
      "34   2.0   0.0   2.0   2.0   2.0   2.0   2.0   0.0   0.0   2.0  ...   \n",
      "35   2.0   0.0   2.0   2.0   2.0   2.0   2.0   0.0   0.0   2.0  ...   \n",
      "36   2.0   0.0   2.0   2.0   2.0   2.0   2.0   0.0   0.0   2.0  ...   \n",
      "\n",
      "          x732           x556  x795  x800        x465          x5         x31  \\\n",
      "0    39.648270  158997.701854   2.0   0.0   4911109.0   4911109.0   4877171.0   \n",
      "1    49.224139  164935.930015   2.0   0.0   5219840.0   5219840.0   5197824.0   \n",
      "2    97.201590   38982.313196   9.0   0.0   1422633.0   1422633.0   1389889.0   \n",
      "3    41.759264  101726.328688   0.0  13.0   1870879.0   1870879.0   1859945.0   \n",
      "4    60.673209  225298.087229   2.0   0.0   4240198.0   4240198.0   4214553.0   \n",
      "5   264.011755   91546.264276   0.0   2.0   3105543.0   3105543.0   3059552.0   \n",
      "6   104.917847   36473.622298   0.0   5.0   2329983.0   2329983.0   2317964.0   \n",
      "7    57.282799  255970.236915   2.0   0.0   4380478.0   4380478.0   4351530.0   \n",
      "8   101.067357   42151.053528   1.0   7.0   1572295.0   1572295.0   1547968.0   \n",
      "9    68.486592  268070.698775   2.0   0.0   6036423.0   6036423.0   6012522.0   \n",
      "10   69.781585   88410.780543   2.0   0.0   6984188.0   6984188.0   6961746.0   \n",
      "11   26.137686   61821.195362   2.0   0.0   4071520.0   4071520.0   4057711.0   \n",
      "12  253.790376  138617.878287   2.0   0.0   8212365.0   8212365.0   8177846.0   \n",
      "13  740.722283   16563.128414   1.0  10.0   1106965.0   1106965.0   1096851.0   \n",
      "14   66.071367  304259.939819   2.0   0.0   7660587.0   7660587.0   7633616.0   \n",
      "15   35.992333  262971.722013   2.0   0.0   4738132.0   4738132.0   4724437.0   \n",
      "16   48.375311   88437.121079   2.0   0.0   5892529.0   5892529.0   5874451.0   \n",
      "17   44.475055  217420.791668   2.0   0.0   6151618.0   6151618.0   6145375.0   \n",
      "18  214.164134  365762.920157   2.0   0.0   7653029.0   7653029.0   7653029.0   \n",
      "19  114.286667  109013.676122   0.0   2.0   3378861.0   3378861.0   3359021.0   \n",
      "20   38.516670  158967.404636   2.0   0.0   5453791.0   5453791.0   5445064.0   \n",
      "21   49.549145   75998.829479   2.0   0.0   5025467.0   5025467.0   5015153.0   \n",
      "22   88.098818  287110.808116   2.0   0.0   7467721.0   7467721.0   7467721.0   \n",
      "23   67.968792  151742.684178   2.0   0.0   8300154.0   8300154.0   8283606.0   \n",
      "24  151.861063   23493.188541   0.0   2.0   2561778.0   2561778.0   2544984.0   \n",
      "25   50.412546  191671.652537   2.0   0.0   6420100.0   6420100.0   6409988.0   \n",
      "26   38.196114   56577.462807   2.0   0.0   3451266.0   3451266.0   3437807.0   \n",
      "27   93.512055  292980.481505   2.0   0.0   7615338.0   7615338.0   7601339.0   \n",
      "28   51.930887  234227.799471   2.0   0.0   6067011.0   6067011.0   6059998.0   \n",
      "29   11.192741   53821.579249   0.0   5.0    887574.0    887574.0    873258.0   \n",
      "30  223.938532   74916.389171   1.0   6.0    964664.0    964664.0    937115.0   \n",
      "31  141.849183   53041.163062   1.0   0.0   2530825.0   2530825.0   2522120.0   \n",
      "32  167.820837   41613.696368   1.0   4.0   1114027.0   1114027.0   1106366.0   \n",
      "33   14.080680   55618.020373   2.0   0.0   3179308.0   3179308.0   3172949.0   \n",
      "34  113.834056  190989.904377   2.0   0.0   7268939.0   7268939.0   7201940.0   \n",
      "35   36.472606  149206.787222   2.0   0.0  12527323.0  12527323.0  12514797.0   \n",
      "36   23.803038   29070.197118   2.0   0.0   3007692.0   3007692.0   3001281.0   \n",
      "\n",
      "          x265           x522          x480  \n",
      "0    4911109.0  179545.261866  3.648356e+05  \n",
      "1    5219840.0  141843.467345  6.707469e+05  \n",
      "2    1422633.0   46098.691246  2.924083e+05  \n",
      "3    1870879.0   79159.086603  5.239882e+04  \n",
      "4    4240198.0   53948.105990  2.140041e+05  \n",
      "5    3105543.0  112739.657929  2.054458e+05  \n",
      "6    2329983.0   34863.431057  1.526956e+05  \n",
      "7    4380478.0   75621.646648  3.733162e+05  \n",
      "8    1572295.0   66247.747164  7.356345e+04  \n",
      "9    6036423.0  317256.389282  4.671268e+05  \n",
      "10   6984188.0  401414.563887  6.521295e+05  \n",
      "11   4071520.0  189156.184504  6.686128e+05  \n",
      "12   8212365.0  385040.686458  2.095156e+05  \n",
      "13   1106965.0   40015.032571  3.562380e+03  \n",
      "14   7660587.0  382367.712719  1.464514e+06  \n",
      "15   4738132.0  150102.237534  1.895510e+06  \n",
      "16   5892529.0  303957.102877  4.098963e+05  \n",
      "17   6151618.0  329656.036340  6.681016e+05  \n",
      "18   7653029.0  172450.038245  2.179239e+06  \n",
      "19   3378861.0   69392.999272  2.937067e+05  \n",
      "20   5453791.0   63262.085445  3.896543e+05  \n",
      "21   5025467.0  140049.509262  6.940708e+05  \n",
      "22   7467721.0  228738.776668  9.036843e+05  \n",
      "23   8300154.0  484336.997213  8.173437e+05  \n",
      "24   2561778.0  104258.156538  2.557768e+05  \n",
      "25   6420100.0  300333.245562  5.181070e+05  \n",
      "26   3451266.0  166638.603251  4.804872e+05  \n",
      "27   7615338.0  587110.091925  4.484479e+05  \n",
      "28   6067011.0  545963.229026  8.232014e+05  \n",
      "29    887574.0   26092.814759  4.662108e+04  \n",
      "30    964664.0   70992.729640  2.149891e+05  \n",
      "31   2530825.0   73026.095693  2.054401e+05  \n",
      "32   1114027.0   26053.246146  1.538384e+05  \n",
      "33   3179308.0  142074.161386  1.106763e+06  \n",
      "34   7268939.0  391033.610980  2.718306e+05  \n",
      "35  12527323.0  370288.974139  5.813893e+05  \n",
      "36   3007692.0   98641.247811  1.067534e+06  \n",
      "\n",
      "[37 rows x 56 columns]\n",
      "| Model          | CV Score      |   Features | Top Features             |   CV Folds |\n",
      "|:---------------|:--------------|-----------:|:-------------------------|-----------:|\n",
      "| SMOTE Pipeline | 0.500 ± 0.000 |        812 | ['x791', 'x787', 'x797'] |          5 |\n",
      "    anxiety  other  unipolar  ct  bipolar  substance  asrs  add  wurs  cpt_ii  \\\n",
      "22        2      2         2   2        2          2     0    2     0       0   \n",
      "27        2      2         2   2        2          2     0    2     0       0   \n",
      "40        0      0         0   1        0          0    52    0     0       1   \n",
      "38        1      0         1   1        0          0    15    0    30       1   \n",
      "33        2      2         2   2        2          2     0    2     0       0   \n",
      "39        0      0         0   0        0          0    38    1    34       1   \n",
      "42        0      0         0   0        0          1    28    0    25       1   \n",
      "6         2      2         2   2        2          2     0    2     0       0   \n",
      "5         0      1         1   1        0          0    62    0    83       1   \n",
      "21        2      2         2   2        2          2     0    2     0       0   \n",
      "8         2      2         2   2        2          2     0    2     0       0   \n",
      "28        2      2         2   2        2          2     0    2     0       0   \n",
      "9         2      2         2   2        2          2     0    2     0       0   \n",
      "37        1      0         0   1        1          1    46    0    57       1   \n",
      "30        2      2         2   2        2          2     0    2     0       0   \n",
      "15        2      2         2   2        2          2     0    2     0       0   \n",
      "23        2      2         2   2        2          2     0    2     0       0   \n",
      "7         2      2         2   2        2          2     0    2     0       0   \n",
      "36        2      2         2   2        2          2     0    2     0       0   \n",
      "2         0      1         0   0        0          0     0    0    48       1   \n",
      "26        2      2         2   2        2          2     0    2     0       0   \n",
      "32        2      2         2   2        2          2     0    2     0       0   \n",
      "10        2      2         2   2        2          2     0    2     0       0   \n",
      "16        2      2         2   2        2          2     0    2     0       0   \n",
      "43        0      0         1   0        0          0    42    1    40       1   \n",
      "12        2      2         2   2        2          2     0    2     0       0   \n",
      "11        2      2         2   2        2          2     0    2     0       0   \n",
      "35        2      2         2   2        2          2     0    2     0       0   \n",
      "18        2      2         2   2        2          2     0    2     0       0   \n",
      "0         1      1         0   0        0          1    38    0    42       0   \n",
      "41        1      1         0   1        1          0    34    0    33       1   \n",
      "45        1      0         0   1        1          0    54    0    60       1   \n",
      "44        1      1         0   1        1          1    63    0    70       1   \n",
      "34        2      2         2   2        2          2     0    2     0       0   \n",
      "25        2      2         2   2        2          2     0    2     0       0   \n",
      "31        2      2         2   2        2          2     0    2     0       0   \n",
      "17        2      2         2   2        2          2     0    2     0       0   \n",
      "\n",
      "    ...  acc__absolute_sum_of_changes  \\\n",
      "22  ...                     2624537.0   \n",
      "27  ...                     3069180.0   \n",
      "40  ...                     1086686.0   \n",
      "38  ...                     1138564.0   \n",
      "33  ...                     2827474.0   \n",
      "39  ...                     1521044.0   \n",
      "42  ...                     1401681.0   \n",
      "6   ...                     2659068.0   \n",
      "5   ...                     1018014.0   \n",
      "21  ...                     3161490.0   \n",
      "8   ...                     3728585.0   \n",
      "28  ...                     2377014.0   \n",
      "9   ...                     4088143.0   \n",
      "37  ...                      629976.0   \n",
      "30  ...                     3795267.0   \n",
      "15  ...                     2930994.0   \n",
      "23  ...                     3198858.0   \n",
      "7   ...                     2906866.0   \n",
      "36  ...                     3881062.0   \n",
      "2   ...                     1843016.0   \n",
      "26  ...                     2700964.0   \n",
      "32  ...                     2722494.0   \n",
      "10  ...                     3567043.0   \n",
      "16  ...                     4366966.0   \n",
      "43  ...                     1406382.0   \n",
      "12  ...                     3364715.0   \n",
      "11  ...                     2046288.0   \n",
      "35  ...                     3790656.0   \n",
      "18  ...                     3077572.0   \n",
      "0   ...                      549198.0   \n",
      "41  ...                      584326.0   \n",
      "45  ...                     1464952.0   \n",
      "44  ...                      679916.0   \n",
      "34  ...                     1710933.0   \n",
      "25  ...                     3561960.0   \n",
      "31  ...                     5937004.0   \n",
      "17  ...                     1990051.0   \n",
      "\n",
      "    acc__fft_coefficient__attr_\"\"\"\"abs\"\"\"\"__coeff_91  mdq_pos  hads_d  \\\n",
      "22                                     158997.701854        2       0   \n",
      "27                                     164935.930015        2       0   \n",
      "40                                      38982.313196        9       0   \n",
      "38                                     101726.328688        0      13   \n",
      "33                                     225298.087229        2       0   \n",
      "39                                      91546.264276        0       2   \n",
      "42                                      36473.622298        0       5   \n",
      "6                                      255970.236915        2       0   \n",
      "5                                       42151.053528        1       7   \n",
      "21                                     268070.698775        2       0   \n",
      "8                                       88410.780543        2       0   \n",
      "28                                      61821.195362        2       0   \n",
      "9                                      138617.878287        2       0   \n",
      "37                                      16563.128414        1      10   \n",
      "30                                     304259.939819        2       0   \n",
      "15                                     262971.722013        2       0   \n",
      "23                                      88437.121079        2       0   \n",
      "7                                      217420.791668        2       0   \n",
      "36                                     365762.920157        2       0   \n",
      "2                                      109013.676122        0       2   \n",
      "26                                     158967.404636        2       0   \n",
      "32                                      75998.829479        2       0   \n",
      "10                                     287110.808116        2       0   \n",
      "16                                     151742.684178        2       0   \n",
      "43                                      23493.188541        0       2   \n",
      "12                                     191671.652537        2       0   \n",
      "11                                      56577.462807        2       0   \n",
      "35                                     292980.481505        2       0   \n",
      "18                                     234227.799471        2       0   \n",
      "0                                       53821.579249        0       5   \n",
      "41                                      74916.389171        1       6   \n",
      "45                                      53041.163062        1       0   \n",
      "44                                      41613.696368        1       4   \n",
      "34                                      55618.020373        2       0   \n",
      "25                                     190989.904377        2       0   \n",
      "31                                     149206.787222        2       0   \n",
      "17                                      29070.197118        2       0   \n",
      "\n",
      "    acc__fft_coefficient__attr_\"\"\"\"abs\"\"\"\"__coeff_0  acc__sum_values  \\\n",
      "22                                        4911109.0        4911109.0   \n",
      "27                                        5219840.0        5219840.0   \n",
      "40                                        1422633.0        1422633.0   \n",
      "38                                        1870879.0        1870879.0   \n",
      "33                                        4240198.0        4240198.0   \n",
      "39                                        3105543.0        3105543.0   \n",
      "42                                        2329983.0        2329983.0   \n",
      "6                                         4380478.0        4380478.0   \n",
      "5                                         1572295.0        1572295.0   \n",
      "21                                        6036423.0        6036423.0   \n",
      "8                                         6984188.0        6984188.0   \n",
      "28                                        4071520.0        4071520.0   \n",
      "9                                         8212365.0        8212365.0   \n",
      "37                                        1106965.0        1106965.0   \n",
      "30                                        7660587.0        7660587.0   \n",
      "15                                        4738132.0        4738132.0   \n",
      "23                                        5892529.0        5892529.0   \n",
      "7                                         6151618.0        6151618.0   \n",
      "36                                        7653029.0        7653029.0   \n",
      "2                                         3378861.0        3378861.0   \n",
      "26                                        5453791.0        5453791.0   \n",
      "32                                        5025467.0        5025467.0   \n",
      "10                                        7467721.0        7467721.0   \n",
      "16                                        8300154.0        8300154.0   \n",
      "43                                        2561778.0        2561778.0   \n",
      "12                                        6420100.0        6420100.0   \n",
      "11                                        3451266.0        3451266.0   \n",
      "35                                        7615338.0        7615338.0   \n",
      "18                                        6067011.0        6067011.0   \n",
      "0                                          887574.0         887574.0   \n",
      "41                                         964664.0         964664.0   \n",
      "45                                        2530825.0        2530825.0   \n",
      "44                                        1114027.0        1114027.0   \n",
      "34                                        3179308.0        3179308.0   \n",
      "25                                        7268939.0        7268939.0   \n",
      "31                                       12527323.0       12527323.0   \n",
      "17                                        3007692.0        3007692.0   \n",
      "\n",
      "    acc__fft_coefficient__attr_\"\"\"\"real\"\"\"\"__coeff_0  \\\n",
      "22                                         4911109.0   \n",
      "27                                         5219840.0   \n",
      "40                                         1422633.0   \n",
      "38                                         1870879.0   \n",
      "33                                         4240198.0   \n",
      "39                                         3105543.0   \n",
      "42                                         2329983.0   \n",
      "6                                          4380478.0   \n",
      "5                                          1572295.0   \n",
      "21                                         6036423.0   \n",
      "8                                          6984188.0   \n",
      "28                                         4071520.0   \n",
      "9                                          8212365.0   \n",
      "37                                         1106965.0   \n",
      "30                                         7660587.0   \n",
      "15                                         4738132.0   \n",
      "23                                         5892529.0   \n",
      "7                                          6151618.0   \n",
      "36                                         7653029.0   \n",
      "2                                          3378861.0   \n",
      "26                                         5453791.0   \n",
      "32                                         5025467.0   \n",
      "10                                         7467721.0   \n",
      "16                                         8300154.0   \n",
      "43                                         2561778.0   \n",
      "12                                         6420100.0   \n",
      "11                                         3451266.0   \n",
      "35                                         7615338.0   \n",
      "18                                         6067011.0   \n",
      "0                                           887574.0   \n",
      "41                                          964664.0   \n",
      "45                                         2530825.0   \n",
      "44                                         1114027.0   \n",
      "34                                         3179308.0   \n",
      "25                                         7268939.0   \n",
      "31                                        12527323.0   \n",
      "17                                         3007692.0   \n",
      "\n",
      "    acc__sum_of_reoccurring_data_points  \\\n",
      "22                            4877171.0   \n",
      "27                            5197824.0   \n",
      "40                            1389889.0   \n",
      "38                            1859945.0   \n",
      "33                            4214553.0   \n",
      "39                            3059552.0   \n",
      "42                            2317964.0   \n",
      "6                             4351530.0   \n",
      "5                             1547968.0   \n",
      "21                            6012522.0   \n",
      "8                             6961746.0   \n",
      "28                            4057711.0   \n",
      "9                             8177846.0   \n",
      "37                            1096851.0   \n",
      "30                            7633616.0   \n",
      "15                            4724437.0   \n",
      "23                            5874451.0   \n",
      "7                             6145375.0   \n",
      "36                            7653029.0   \n",
      "2                             3359021.0   \n",
      "26                            5445064.0   \n",
      "32                            5015153.0   \n",
      "10                            7467721.0   \n",
      "16                            8283606.0   \n",
      "43                            2544984.0   \n",
      "12                            6409988.0   \n",
      "11                            3437807.0   \n",
      "35                            7601339.0   \n",
      "18                            6059998.0   \n",
      "0                              873258.0   \n",
      "41                             937115.0   \n",
      "45                            2522120.0   \n",
      "44                            1106366.0   \n",
      "34                            3172949.0   \n",
      "25                            7201940.0   \n",
      "31                           12514797.0   \n",
      "17                            3001281.0   \n",
      "\n",
      "    acc__fft_coefficient__attr_\"\"\"\"abs\"\"\"\"__coeff_57  \\\n",
      "22                                     179545.261866   \n",
      "27                                     141843.467345   \n",
      "40                                      46098.691246   \n",
      "38                                      79159.086603   \n",
      "33                                      53948.105990   \n",
      "39                                     112739.657929   \n",
      "42                                      34863.431057   \n",
      "6                                       75621.646648   \n",
      "5                                       66247.747164   \n",
      "21                                     317256.389282   \n",
      "8                                      401414.563887   \n",
      "28                                     189156.184504   \n",
      "9                                      385040.686458   \n",
      "37                                      40015.032571   \n",
      "30                                     382367.712719   \n",
      "15                                     150102.237534   \n",
      "23                                     303957.102877   \n",
      "7                                      329656.036340   \n",
      "36                                     172450.038245   \n",
      "2                                       69392.999272   \n",
      "26                                      63262.085445   \n",
      "32                                     140049.509262   \n",
      "10                                     228738.776668   \n",
      "16                                     484336.997213   \n",
      "43                                     104258.156538   \n",
      "12                                     300333.245562   \n",
      "11                                     166638.603251   \n",
      "35                                     587110.091925   \n",
      "18                                     545963.229026   \n",
      "0                                       26092.814759   \n",
      "41                                      70992.729640   \n",
      "45                                      73026.095693   \n",
      "44                                      26053.246146   \n",
      "34                                     142074.161386   \n",
      "25                                     391033.610980   \n",
      "31                                     370288.974139   \n",
      "17                                      98641.247811   \n",
      "\n",
      "    acc__fft_coefficient__attr_\"\"\"\"abs\"\"\"\"__coeff_15  \n",
      "22                                      3.648356e+05  \n",
      "27                                      6.707469e+05  \n",
      "40                                      2.924083e+05  \n",
      "38                                      5.239882e+04  \n",
      "33                                      2.140041e+05  \n",
      "39                                      2.054458e+05  \n",
      "42                                      1.526956e+05  \n",
      "6                                       3.733162e+05  \n",
      "5                                       7.356345e+04  \n",
      "21                                      4.671268e+05  \n",
      "8                                       6.521295e+05  \n",
      "28                                      6.686128e+05  \n",
      "9                                       2.095156e+05  \n",
      "37                                      3.562380e+03  \n",
      "30                                      1.464514e+06  \n",
      "15                                      1.895510e+06  \n",
      "23                                      4.098963e+05  \n",
      "7                                       6.681016e+05  \n",
      "36                                      2.179239e+06  \n",
      "2                                       2.937067e+05  \n",
      "26                                      3.896543e+05  \n",
      "32                                      6.940708e+05  \n",
      "10                                      9.036843e+05  \n",
      "16                                      8.173437e+05  \n",
      "43                                      2.557768e+05  \n",
      "12                                      5.181070e+05  \n",
      "11                                      4.804872e+05  \n",
      "35                                      4.484479e+05  \n",
      "18                                      8.232014e+05  \n",
      "0                                       4.662108e+04  \n",
      "41                                      2.149891e+05  \n",
      "45                                      2.054401e+05  \n",
      "44                                      1.538384e+05  \n",
      "34                                      1.106763e+06  \n",
      "25                                      2.718306e+05  \n",
      "31                                      5.813893e+05  \n",
      "17                                      1.067534e+06  \n",
      "\n",
      "[37 rows x 56 columns]\n",
      "\n",
      "    [模型报告]\n",
      "    测试集AUC: 0.938\n",
      "    SMOTE参数: k_neighbors=3\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "# ===================== 基础依赖导入 =====================\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import ADASYN, SMOTE\n",
    "from imblearn.under_sampling import NearMiss\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.metrics import balanced_accuracy_score, make_scorer, roc_auc_score\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, clone\n",
    "from sklearn.utils.validation import check_X_y\n",
    "from sklearn.exceptions import NotFittedError\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import shap\n",
    "\n",
    "# ===================== 修复特征选择器 =====================\n",
    "class EnhancedFeatureSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, fdr_levels = 0.05, min_features=5, alpha=0.01, max_iter=20000):\n",
    "        self.fdr_levels = fdr_levels\n",
    "        self.min_features = max(min_features, 3)\n",
    "        self.alpha = alpha\n",
    "        self.max_iter = max_iter\n",
    "        self.primary_cols_ = []    # 首次选择的列名\n",
    "        self.primary_idx_ = []     # 首次选择的列索引\n",
    "        self.secondary_mask_ = []  # 二次选择的布尔掩码\n",
    "        self.scaler_ = None        # 需要初始化scaler_\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # 初始特征选择\n",
    "        self._primary_selection(X, y)  # 修正方法名\n",
    "        \n",
    "        # 准备二次选择数据\n",
    "        X_primary = self._get_primary_features(X)\n",
    "        \n",
    "        # 标准化处理\n",
    "        self.scaler_ = StandardScaler().fit(X_primary)\n",
    "        X_scaled = self.scaler_.transform(X_primary)\n",
    "        \n",
    "        # 二次特征选择\n",
    "        self._secondary_selection(X_scaled, y)\n",
    "        return self\n",
    "\n",
    "    def _primary_selection(self, X, y):\n",
    "        \"\"\"初次特征选择（FDR/方差）\"\"\"\n",
    "        # 统一使用正确的属性名\n",
    "        self.primary_cols_ = []\n",
    "        \n",
    "        if hasattr(X, 'columns'):\n",
    "            df_X = X\n",
    "        else:\n",
    "            df_X = pd.DataFrame(X, columns=[f\"x{i}\" for i in range(X.shape[1])])\n",
    "\n",
    "        # FDR选择逻辑\n",
    "        fdr = self.fdr_levels\n",
    "        try:\n",
    "            X_selected = select_features(df_X, y, fdr_level=fdr)\n",
    "            print(X_selected)\n",
    "            if len(X_selected.columns) >= self.min_features:\n",
    "                    self.primary_cols_ = X_selected.columns.tolist()\n",
    "        except Exception as e:\n",
    "                print(f\"FDR {fdr} 失败: {str(e)}\")\n",
    "        \n",
    "        # 保底策略\n",
    "        if not self.primary_cols_:\n",
    "            print(\"启用方差保底选择\")\n",
    "            variances = np.var(df_X, axis=0)\n",
    "            selected_idx = np.argsort(variances)[-self.min_features:]\n",
    "            self.primary_cols_ = df_X.columns[selected_idx].tolist()\n",
    "        \n",
    "        # 记录列索引\n",
    "        self.primary_idx_ = [df_X.columns.get_loc(col) for col in self.primary_cols_]\n",
    "\n",
    "    def _secondary_selection(self, X, y):\n",
    "        \"\"\"二次特征选择（模型筛选）\"\"\"\n",
    "        try:\n",
    "            en = LassoCV(\n",
    "                alphas=[self.alpha],\n",
    "                max_iter=self.max_iter,\n",
    "                cv=3,\n",
    "                random_state=42\n",
    "            )\n",
    "            en.fit(X, y)\n",
    "            self.secondary_mask_ = en.coef_ != 0\n",
    "            \n",
    "            # 保底机制\n",
    "            if np.sum(self.secondary_mask_) < self.min_features:\n",
    "                print(f\"二次选择特征不足({np.sum(self.secondary_mask_)}个)，启用重要性排序\")\n",
    "                top_idx = np.argsort(np.abs(en.coef_))[::-1][:self.min_features]\n",
    "                self.secondary_mask_ = np.zeros_like(en.coef_, dtype=bool)\n",
    "                self.secondary_mask_[top_idx] = True\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"模型选择失败: {str(e)}, 使用全部初选特征\")\n",
    "            self.secondary_mask_ = np.ones(X.shape[1], dtype=bool)\n",
    "\n",
    "    def transform(self, X):\n",
    "        # 获取首次选择特征\n",
    "        X_primary = self._get_primary_features(X)\n",
    "        \n",
    "        # 标准化\n",
    "        if self.scaler_ is None:\n",
    "            raise NotFittedError(\"需要先调用fit方法\")\n",
    "        X_scaled = self.scaler_.transform(X_primary)\n",
    "        \n",
    "        # 应用二次选择\n",
    "        X_final = X_scaled[:, self.secondary_mask_]\n",
    "        \n",
    "        # 最终维度验证\n",
    "        if X_final.shape[1] == 0:\n",
    "            raise ValueError(\"最终特征数量为0，请检查选择参数\")\n",
    "        \n",
    "        assert X_final.shape[1] == len(self.get_feature_names()), \"特征维度不匹配\"\n",
    "\n",
    "            \n",
    "        return X_final\n",
    "\n",
    "    def _get_primary_features(self, X):\n",
    "        \"\"\"统一获取首次选择特征\"\"\"\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            return X[self.primary_cols_].values\n",
    "        else:\n",
    "            return X[:, self.primary_idx_]\n",
    "\n",
    "    def get_params(self, deep=True):\n",
    "        return {'fdr_levels': self.fdr_levels,\n",
    "                'min_features': self.min_features,\n",
    "                'alpha': self.alpha}\n",
    "\n",
    "    def set_params(self, **params):\n",
    "        if 'fdr_levels' in params:\n",
    "            params['fdr_levels'] = tuple(params['fdr_levels']) if isinstance(params['fdr_levels'], list) else params['fdr_levels']\n",
    "        for key, value in params.items():\n",
    "            setattr(self, key, value)\n",
    "        return self\n",
    "    \n",
    "    def get_feature_names(self):\n",
    "        \"\"\"获取最终选择的特征名称\"\"\"\n",
    "        return [col for col, mask in zip(self.primary_cols_, self.secondary_mask_) if mask]\n",
    "\n",
    "# ===================== 数据准备 ===================== \n",
    "# 转换时保留原始数据副本\n",
    "raw_dataX = dataX_hrv0.to_pandas().copy()\n",
    "raw_dataY = dataY_hrv0.to_pandas()[\"ADHD\"].copy()\n",
    "\n",
    "# 索引对齐增强版\n",
    "def safe_align_index(X, y):\n",
    "    \"\"\"安全对齐索引的三重校验\"\"\"\n",
    "    # 第一层校验：索引完全匹配\n",
    "    if X.index.equals(y.index):\n",
    "        return X, y\n",
    "    \n",
    "    # 第二层校验：ID列匹配\n",
    "    if 'ID' in X.columns and 'ID' in y.columns:\n",
    "        common_ids = np.intersect1d(X['ID'], y['ID'])\n",
    "        X = X[X['ID'].isin(common_ids)].set_index('ID')\n",
    "        y = y[y['ID'].isin(common_ids)].set_index('ID')\n",
    "    else:\n",
    "        # 第三层校验：强制重置索引\n",
    "        X = X.reset_index(drop=True)\n",
    "        y = y.reset_index(drop=True)\n",
    "        print(\"警告：无法对齐索引，已重置索引\")\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "\n",
    "dataX_pd, dataY_pd = safe_align_index(raw_dataX, raw_dataY)\n",
    "dataX_pd = dataX_pd.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# 增强型特征去重（处理大小写和空格）\n",
    "dataX_pd.columns = dataX_pd.columns.str.strip().str.lower()\n",
    "dataX_pd = dataX_pd.loc[:, ~dataX_pd.columns.duplicated(keep='first')]\n",
    "\n",
    "# 动态缺失值处理（保留原始数据）\n",
    "missing_threshold = 0.3\n",
    "missing_cols = dataX_pd.columns[dataX_pd.isna().mean() > missing_threshold]\n",
    "if len(missing_cols) > 0:\n",
    "    print(f\"删除高缺失率列: {missing_cols.tolist()}\")\n",
    "    dataX_pd = dataX_pd.drop(columns=missing_cols)\n",
    "\n",
    "# 数据分割（先分割再填充）\n",
    "X_temp, X_test_raw, y_temp, y_test = train_test_split(\n",
    "    dataX_pd, dataY_pd,\n",
    "    test_size=0.2,\n",
    "    stratify=dataY_pd if dataY_pd.nunique() > 1 else None,\n",
    "    random_state=6\n",
    ")\n",
    "\n",
    "# 安全填充（用训练集中位数填充）\n",
    "train_median = X_temp.median()\n",
    "X_train_raw = X_temp.fillna(train_median)\n",
    "X_test_raw = X_test_raw.fillna(train_median)  # 使用训练集统计量\n",
    "\n",
    "# 最终数据校验\n",
    "print(f\"[数据报告] 总样本: {len(dataX_pd)} | 特征数: {X_train_raw.shape[1]}\")\n",
    "print(f\"训练集正样本比例: {y_temp.mean():.1%} | 测试集正样本比例: {y_test.mean():.1%}\")\n",
    "\n",
    "# 特征类型转换（保留列名）\n",
    "X_train_raw = X_train_raw.astype(np.float64)\n",
    "X_test_raw = X_test_raw.astype(np.float64)\n",
    "\n",
    "\n",
    "X_train_raw, X_test_raw, y_train, y_test = train_test_split(\n",
    "    dataX_pd, dataY_pd,\n",
    "    test_size=0.2,\n",
    "    stratify=dataY_pd,\n",
    "    random_state=6\n",
    ")\n",
    "\n",
    "# ===================== 动态参数配置 =====================\n",
    "n_positive = sum(y_train == 1)\n",
    "safe_n_neighbors = max(1, min(3, (n_positive - 1) // 2))  # 修正1：避免除零问题\n",
    "\n",
    "# 交叉验证策略优化\n",
    "if n_positive < 5:\n",
    "    cv_strategy = StratifiedKFold(n_splits=3, shuffle=True)\n",
    "elif 5 <= n_positive < 20:\n",
    "    cv_strategy = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "else:\n",
    "    cv_strategy = StratifiedKFold(n_splits=10, shuffle=True)\n",
    "\n",
    "# 模型参数配置修正\n",
    "base_params = {\n",
    "    'random_state': 42,\n",
    "    'categorical_features': None,\n",
    "    'monotonic_cst': None,\n",
    "    'scoring': 'balanced_accuracy'  # 修正2：使用原生支持的正则化方式\n",
    "}\n",
    "\n",
    "if n_positive < 5:\n",
    "    scoring = make_scorer(roc_auc_score, needs_proba=True)  # 修正3：需要概率预测\n",
    "    model_config = {\n",
    "        **base_params,\n",
    "        'max_depth': 2,              # 限制树深\n",
    "        'min_samples_leaf': 20       # 防止过拟合\n",
    "    }\n",
    "else:\n",
    "    scoring = make_scorer(balanced_accuracy_score)\n",
    "    model_config = {\n",
    "        **base_params,\n",
    "        'learning_rate': 0.05,\n",
    "        'max_depth': 3,\n",
    "        'class_weight': None,        # 修正4：HistGradientBoosting无此参数\n",
    "        'l2_regularization': 0.1     # 改用正确的正则化参数\n",
    "    }\n",
    "\n",
    "# 安全邻居数最终校验（修正5）\n",
    "safe_n_neighbors = min(safe_n_neighbors, n_positive - 1) if n_positive > 1 else 0\n",
    "\n",
    "# ===================== 管道构建 =====================\n",
    "def create_SMOTE_pipeline():\n",
    "    return Pipeline([\n",
    "    ('feature_selector', EnhancedFeatureSelector()),\n",
    "    ('smote', SMOTE(\n",
    "        sampling_strategy=0.5,  # 将少数类扩至多数类的50%\n",
    "        k_neighbors=3,          # 降低k值适应小样本\n",
    "        random_state=42\n",
    "    )),\n",
    "    ('classifier', HistGradientBoostingClassifier())\n",
    "])\n",
    "\n",
    "# ===================== 模型列表 =====================\n",
    "models = [\n",
    "    create_SMOTE_pipeline()\n",
    "]\n",
    "\n",
    "# ===================== 验证流程 =====================\n",
    "\n",
    "\n",
    "results = []\n",
    "for model in models:\n",
    "    try:\n",
    "        # 数据准备增强\n",
    "        X_array = X_train_raw.astype(np.float64).values\n",
    "        y_array = y_train.astype(np.int32).values  # 修改点1：使用int32节省内存\n",
    "        \n",
    "        # 动态调整交叉验证\n",
    "        cv_strategy = StratifiedKFold(\n",
    "            n_splits=min(5, np.bincount(y_array).min()),  # 根据最少类别样本数调整\n",
    "            shuffle=True,\n",
    "            random_state=42\n",
    "        )\n",
    "        \n",
    "        # 交叉验证流程\n",
    "        scores = cross_val_score(\n",
    "            clone(model),\n",
    "            X_array,\n",
    "            y_array,\n",
    "            cv=cv_strategy,  # 修改点2：动态交叉验证\n",
    "            scoring=scoring,\n",
    "            n_jobs=-1,       # 修改点3：启用并行\n",
    "            error_score='raise'\n",
    "        )\n",
    "        \n",
    "        # 全量训练\n",
    "        final_model = clone(model).fit(X_array, y_array)\n",
    "        \n",
    "        # 特征重要性获取优化\n",
    "        classifier = final_model.named_steps['classifier']\n",
    "        selector = final_model.named_steps['feature_selector']\n",
    "        \n",
    "        # 修改点4：统一特征重要性获取方式\n",
    "        if hasattr(classifier, 'feature_importances_'):\n",
    "            importances = classifier.feature_importances_\n",
    "        elif hasattr(classifier, 'coef_'):\n",
    "            importances = np.abs(classifier.coef_[0])\n",
    "        else:\n",
    "            explainer = shap.TreeExplainer(classifier)\n",
    "            shap_values = explainer.shap_values(X_array)\n",
    "            importances = np.abs(shap_values).mean(axis=0)\n",
    "        \n",
    "        # 获取实际选中的特征名称\n",
    "        try:\n",
    "            selected_features = selector.get_feature_names()  # 修改点5\n",
    "            top_features = selected_features[:3]\n",
    "        except Exception as e:\n",
    "            print(f\"特征名称获取失败: {str(e)}\")\n",
    "            top_features = []\n",
    "        \n",
    "        results.append({\n",
    "            'Model': name,\n",
    "            'CV Score': f\"{np.mean(scores):.3f} ± {np.std(scores):.3f}\",\n",
    "            'Features': len(importances),\n",
    "            'Top Features': top_features,\n",
    "            'CV Folds': cv_strategy.n_splits  # 新增指标\n",
    "        })\n",
    "        \n",
    "    except Exception as e:\n",
    "        error_msg = f\"{name} 失败: {type(e).__name__} - {str(e)}\"\n",
    "        print(error_msg)\n",
    "        continue\n",
    "\n",
    "# ===================== 结果展示 =====================\n",
    "if results:\n",
    "    result_df = pd.DataFrame(results)\n",
    "    # 添加排序逻辑\n",
    "    result_df['Mean Score'] = result_df['CV Score'].str.extract(r'(\\d+\\.\\d+)').astype(float)\n",
    "    print(result_df.sort_values('Mean Score', ascending=False)\n",
    "                  .drop('Mean Score', axis=1)\n",
    "                  .to_markdown(index=False))\n",
    "else:\n",
    "    print(\"所有模型运行失败，请检查数据\")\n",
    "\n",
    "\n",
    "model = create_SMOTE_pipeline()\n",
    "\n",
    " # 全量训练\n",
    "model.fit(X_train_raw, y_train)\n",
    "    \n",
    "    # 测试评估\n",
    "test_proba = model.predict_proba(X_test_raw)[:, 1]\n",
    "test_auc = roc_auc_score(y_test, test_proba)\n",
    "    \n",
    "    # 结果展示\n",
    "print(f\"\"\"\n",
    "    [模型报告]\n",
    "    测试集AUC: {test_auc:.3f}\n",
    "    SMOTE参数: k_neighbors={model.named_steps['smote'].k_neighbors}\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['trained_model.pkl']"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# 保存训练参数\n",
    "joblib.dump({\n",
    "    'model': model,\n",
    "    'train_median': X_train_raw.median(),\n",
    "    'feature_columns': X_train_raw.columns\n",
    "}, 'trained_model.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
